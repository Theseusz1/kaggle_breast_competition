{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    import timm\nexcept:\n    !pip install /kaggle/input/notebook937eeb7d5c/timm-0.6.12-py3-none-any.whl\ntry:\n    import gdcm\nexcept:\n    !pip install /kaggle/input/rsna-2022-whl/python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ntry:\n    import pylibjpeg\nexcept:\n    !pip install /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n!pip install -q /kaggle/input/rsna-bcd-whl-ds/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T02:02:43.523512Z","iopub.execute_input":"2023-02-19T02:02:43.524060Z","iopub.status.idle":"2023-02-19T02:04:45.778523Z","shell.execute_reply.started":"2023-02-19T02:02:43.523974Z","shell.execute_reply":"2023-02-19T02:04:45.777294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.model_selection import GroupKFold \nfrom sklearn.metrics import f1_score,accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\nfrom tqdm import tqdm\nimport glob\nimport shutil\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport dicomsdl\nfrom joblib import Parallel, delayed\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:45.781639Z","iopub.execute_input":"2023-02-19T02:04:45.782057Z","iopub.status.idle":"2023-02-19T02:04:50.035125Z","shell.execute_reply.started":"2023-02-19T02:04:45.782014Z","shell.execute_reply":"2023-02-19T02:04:50.034011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = glob.glob(\"/kaggle/input/rsna-breast-cancer-detection/test_images/*/*.dcm\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.036934Z","iopub.execute_input":"2023-02-19T02:04:50.037542Z","iopub.status.idle":"2023-02-19T02:04:50.048674Z","shell.execute_reply.started":"2023-02-19T02:04:50.037502Z","shell.execute_reply":"2023-02-19T02:04:50.047707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T02:04:50.051728Z","iopub.execute_input":"2023-02-19T02:04:50.052417Z","iopub.status.idle":"2023-02-19T02:04:50.062277Z","shell.execute_reply.started":"2023-02-19T02:04:50.052380Z","shell.execute_reply":"2023-02-19T02:04:50.060836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = \"/kaggle/temp/\"\nINPUT_SIZE = 1280\nDEVICE = 'cuda'\nos.makedirs(save_path, exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.063945Z","iopub.execute_input":"2023-02-19T02:04:50.064316Z","iopub.status.idle":"2023-02-19T02:04:50.071547Z","shell.execute_reply.started":"2023-02-19T02:04:50.064280Z","shell.execute_reply":"2023-02-19T02:04:50.070508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(save_path)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T02:04:50.072973Z","iopub.execute_input":"2023-02-19T02:04:50.073528Z","iopub.status.idle":"2023-02-19T02:04:50.082590Z","shell.execute_reply.started":"2023-02-19T02:04:50.073491Z","shell.execute_reply":"2023-02-19T02:04:50.081353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\ndf","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T02:04:50.084388Z","iopub.execute_input":"2023-02-19T02:04:50.084834Z","iopub.status.idle":"2023-02-19T02:04:50.109543Z","shell.execute_reply.started":"2023-02-19T02:04:50.084799Z","shell.execute_reply":"2023-02-19T02:04:50.108516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def load_image_dicomsdl(img_path):\n    dataset = dicomsdl.open(img_path)\n    img = dataset.pixelData()\n\n    try:\n            # Load only the variables we need\n            center = dataset[\"WindowCenter\"]\n            width = dataset[\"WindowWidth\"]\n            bits_stored = dataset[\"BitsStored\"]\n            voi_lut_function = dataset[\"VOILUTFunction\"]\n\n            # For sigmoid it's a list, otherwise a single value\n            if isinstance(center, list):\n                center = center[0]\n            if isinstance(width, list):\n                width = width[0]\n\n            # Set y_min, max & range\n            y_min = 0\n            y_max = float(2**bits_stored - 1)\n            y_range = y_max\n\n            # Function with default LINEAR (so for Nan, it will use linear)\n            if voi_lut_function == \"SIGMOID\":\n                img = y_range / (1 + np.exp(-4 * (img - center) / width)) + y_min\n            else:\n                # Checks width for < 1 (in our case not necessary, always >= 750)\n                center -= 0.5\n                width -= 1\n\n                below = img <= (center - width / 2)\n                above = img > (center + width / 2)\n                between = np.logical_and(~below, ~above)\n\n                img[below] = y_min\n                img[above] = y_max\n                if between.any():\n                    img[between] = (\n                        ((img[between] - center) / width + 0.5) * y_range + y_min\n                    )\n    except Exception as e:\n#         dataset = dicoml.open(img_path)\n        img = dataset.pixelData()\n\n\n    img = (img - img.min()) / (img.max() - img.min())\n\n    if dataset[\"PhotometricInterpretation\"] == \"MONOCHROME1\":\n        img = 1 - img\n\n    img = (img * 255).astype(np.uint8)\n\n    return img'''","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.111175Z","iopub.execute_input":"2023-02-19T02:04:50.111683Z","iopub.status.idle":"2023-02-19T02:04:50.119707Z","shell.execute_reply.started":"2023-02-19T02:04:50.111643Z","shell.execute_reply":"2023-02-19T02:04:50.118760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img2roi(img):\n    # Binarize the image\n    bin_img = cv2.threshold(img, 20, 255, cv2.THRESH_BINARY)[1]\n\n    # Make contours around the binarized image, keep only the largest contour\n    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    contour = max(contours, key=cv2.contourArea)\n\n    # Find ROI from largest contour\n    ys = contour.squeeze()[:, 0]\n    xs = contour.squeeze()[:, 1]\n    roi =  img[np.min(xs):np.max(xs), np.min(ys):np.max(ys)]\n    \n    return roi","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.121109Z","iopub.execute_input":"2023-02-19T02:04:50.122350Z","iopub.status.idle":"2023-02-19T02:04:50.132001Z","shell.execute_reply.started":"2023-02-19T02:04:50.122312Z","shell.execute_reply":"2023-02-19T02:04:50.131138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(path, size):\n    patient = path.split('/')[-2]\n    image = path.split('/')[-1][:-4]\n    dicom = dicomsdl.open(path)\n    img = dicom.pixelData(storedvalue=False)\n    img = (img - img.min()) / (img.max()-img.min())\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        img = 1.0- img\n    img = (img*255).astype(np.uint8)\n    img = img2roi(img)\n    final_img = Image.fromarray(img)\n    final_img = final_img.resize((int(INPUT_SIZE/2),int(INPUT_SIZE)),Image.Resampling.LANCZOS)\n    final_img.save(save_path+f\"{patient}_{image}.png\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.136482Z","iopub.execute_input":"2023-02-19T02:04:50.137402Z","iopub.status.idle":"2023-02-19T02:04:50.144821Z","shell.execute_reply.started":"2023-02-19T02:04:50.137367Z","shell.execute_reply":"2023-02-19T02:04:50.144135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def process(path, size):\n    patient = path.split('/')[-2]\n    image = path.split('/')[-1][:-4]\n    img = load_image_dicomsdl(path)\n    final_img = Image.fromarray(img)\n    final_img = final_img.resize((int(INPUT_SIZE/2),int(INPUT_SIZE)),Image.Resampling.LANCZOS)\n    final_img.save(save_path+f\"{patient}_{image}.png\")'''","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:50.146024Z","iopub.execute_input":"2023-02-19T02:04:50.146866Z","iopub.status.idle":"2023-02-19T02:04:50.155965Z","shell.execute_reply.started":"2023-02-19T02:04:50.146832Z","shell.execute_reply":"2023-02-19T02:04:50.154840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = Parallel(n_jobs=4)(\n    delayed(process)(uid, size=INPUT_SIZE)\n    for uid in tqdm(test_images)\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T02:04:50.157495Z","iopub.execute_input":"2023-02-19T02:04:50.157942Z","iopub.status.idle":"2023-02-19T02:04:53.555585Z","shell.execute_reply.started":"2023-02-19T02:04:50.157906Z","shell.execute_reply":"2023-02-19T02:04:53.553639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(save_path)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.560800Z","iopub.execute_input":"2023-02-19T02:04:53.563440Z","iopub.status.idle":"2023-02-19T02:04:53.575184Z","shell.execute_reply.started":"2023-02-19T02:04:53.563389Z","shell.execute_reply":"2023-02-19T02:04:53.574010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from matplotlib import pyplot as plt\nimport cv2\nfig = plt.figure(figsize = (10,10))\nplt.subplot(221)\nimg1 = cv2.imread(save_path+'10008_361203119.png')\nimg1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\nplt.imshow(img1)\nplt.subplot(222)\nimg2 = cv2.imread(save_path+'10008_736471439.png')\nimg2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\nplt.imshow(img2)\nplt.subplot(223)\nimg3 = cv2.imread(save_path+'10008_1591370361.png')\nimg3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\nplt.imshow(img3)\nplt.subplot(224)\nimg4 = cv2.imread(save_path+'10008_68070693.png')\nimg4 = cv2.cvtColor(img4, cv2.COLOR_BGR2RGB)\nplt.imshow(img4)\nplt.show()'''","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.578545Z","iopub.execute_input":"2023-02-19T02:04:53.579269Z","iopub.status.idle":"2023-02-19T02:04:53.587097Z","shell.execute_reply.started":"2023-02-19T02:04:53.579225Z","shell.execute_reply":"2023-02-19T02:04:53.586024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''import torchvision\n\ndef get_transforms(aug=False):\n\n    def transforms(img):\n        img = img.convert('RGB')#.resize((512, 512))\n        if aug:\n            tfm = [\n                torchvision.transforms.RandomHorizontalFlip(0.5),\n                torchvision.transforms.RandomRotation(degrees=(-5, 5)), \n                torchvision.transforms.RandomResizedCrop((1024, 512), scale=(0.8, 1), ratio=(0.45, 0.55)) \n            ]\n        else:\n            tfm = [\n                torchvision.transforms.RandomHorizontalFlip(0.5),\n                torchvision.transforms.Resize((1024, 512))\n            ]\n        img = torchvision.transforms.Compose(tfm + [            \n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=0.2179, std=0.0529),\n            \n        ])(img)\n        return img\n\n    return lambda img: transforms(img)'''\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.588828Z","iopub.execute_input":"2023-02-19T02:04:53.589586Z","iopub.status.idle":"2023-02-19T02:04:53.599026Z","shell.execute_reply.started":"2023-02-19T02:04:53.589534Z","shell.execute_reply":"2023-02-19T02:04:53.598357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations.pytorch.transforms import ToTensorV2\naug_resize_norm = A.Compose([\n    A.Resize(INPUT_SIZE, INPUT_SIZE/2),\n    A.Normalize(),\n    ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.600659Z","iopub.execute_input":"2023-02-19T02:04:53.601547Z","iopub.status.idle":"2023-02-19T02:04:53.608692Z","shell.execute_reply.started":"2023-02-19T02:04:53.601472Z","shell.execute_reply":"2023-02-19T02:04:53.607827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nclass BreastCancerDataSet(torch.utils.data.Dataset):\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, i):\n\n        path = f'{self.path}/{self.df.iloc[i].patient_id}_{self.df.iloc[i].image_id}.png'\n        try:\n            #img = Image.open(path).convert('RGB')\n            img = cv2.imread(path)\n        except Exception as ex:\n            print(path, ex)\n            return None\n\n        if self.transforms is not None:\n            #img = self.transforms(img)\n            img = self.transforms(image=img)['image']\n        return img\n\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.610104Z","iopub.execute_input":"2023-02-19T02:04:53.610846Z","iopub.status.idle":"2023-02-19T02:04:53.619542Z","shell.execute_reply.started":"2023-02-19T02:04:53.610810Z","shell.execute_reply":"2023-02-19T02:04:53.618610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from PIL import Image\nclass BreastCancerDataSet(torch.utils.data.Dataset):\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, i):\n\n        path = f'{self.path}/{self.df.iloc[i].patient_id}_{self.df.iloc[i].image_id}.png'\n        try:\n            img = Image.open(path).convert('RGB')\n        except Exception as ex:\n            print(path, ex)\n            return None\n\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n\n        return img\n\n    def __len__(self):\n        return len(self.df)'''","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.621918Z","iopub.execute_input":"2023-02-19T02:04:53.622805Z","iopub.status.idle":"2023-02-19T02:04:53.635434Z","shell.execute_reply.started":"2023-02-19T02:04:53.622768Z","shell.execute_reply":"2023-02-19T02:04:53.634423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aux_classes = [2,2,6,2,2,2,4,5,2,10,10]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.636463Z","iopub.execute_input":"2023-02-19T02:04:53.637631Z","iopub.status.idle":"2023-02-19T02:04:53.644886Z","shell.execute_reply.started":"2023-02-19T02:04:53.637594Z","shell.execute_reply":"2023-02-19T02:04:53.644008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BreastCancerModel(torch.nn.Module):\n    def __init__(self, aux_classes, model_type, dropout=0.):\n        super().__init__()\n        self.model = timm.create_model(model_type, pretrained=False, drop_rate=dropout)\n\n        self.backbone_dim = self.model(torch.randn(1, 3, 1280, 640)).shape[-1]\n\n        self.nn_cancer = torch.nn.Sequential(\n            torch.nn.Linear(self.backbone_dim, 1),\n        )\n        self.nn_aux = torch.nn.ModuleList([\n            torch.nn.Linear(self.backbone_dim, n) for n in aux_classes\n        ])\n\n    def forward(self, x):\n        # returns logits\n        x = self.model(x)\n\n        cancer = self.nn_cancer(x).squeeze()\n        aux = []\n        for nn in self.nn_aux:\n            aux.append(nn(x).squeeze())\n        return cancer, aux\n\n    def predict(self, x):\n        cancer, aux = self.forward(x)\n        sigaux = []\n        for a in aux:\n            sigaux.append(torch.softmax(a, dim=-1))\n        return torch.sigmoid(cancer), sigaux","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.646543Z","iopub.execute_input":"2023-02-19T02:04:53.646973Z","iopub.status.idle":"2023-02-19T02:04:53.658000Z","shell.execute_reply.started":"2023-02-19T02:04:53.646938Z","shell.execute_reply":"2023-02-19T02:04:53.656607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(path, model=None):\n    data = torch.load(path, map_location=DEVICE)\n    if model is None:\n        model = BreastCancerModel(aux_classes, data['model_type'])\n    model.load_state_dict(data['model'])\n    return model, data['threshold'], data['model_type']\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.659803Z","iopub.execute_input":"2023-02-19T02:04:53.660131Z","iopub.status.idle":"2023-02-19T02:04:53.669008Z","shell.execute_reply.started":"2023-02-19T02:04:53.660105Z","shell.execute_reply":"2023-02-19T02:04:53.668012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nthresholds = []\nMODELS_PATH = '/kaggle/input/efficientmodel/'\nfor fname in tqdm(sorted(os.listdir(MODELS_PATH))):\n    model, thres, model_type = load_model(MODELS_PATH+fname)\n    model = model.to(DEVICE)\n    models.append((model, thres))\n    thresholds.append(thres)\n    print(f'fname:{fname}, model_type:{model_type}, thres:{thres}')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:04:53.670500Z","iopub.execute_input":"2023-02-19T02:04:53.670951Z","iopub.status.idle":"2023-02-19T02:05:12.676716Z","shell.execute_reply.started":"2023-02-19T02:04:53.670916Z","shell.execute_reply":"2023-02-19T02:05:12.675702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_TTA = True\ntop3 = False\ngeomeanpatient = False\ngeomeanpredict =False","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:12.680465Z","iopub.execute_input":"2023-02-19T02:05:12.681696Z","iopub.status.idle":"2023-02-19T02:05:12.692579Z","shell.execute_reply.started":"2023-02-19T02:05:12.681658Z","shell.execute_reply":"2023-02-19T02:05:12.689872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def models_predict(models, ds, max_batches=1e9):\n    dl_test = torch.utils.data.DataLoader(ds, batch_size=16, shuffle=False, num_workers=os.cpu_count())\n    for m, thres in models:\n        m.eval()\n\n    with torch.no_grad():\n        predictions = []\n        for idx, X in enumerate(tqdm(dl_test, mininterval=30)):\n            pred = torch.zeros(len(X), len(models))\n            for idx, (m, thres) in enumerate(models):\n                X = X.to(DEVICE)\n                pred1 = m.predict(X)[0].squeeze()\n                if use_TTA:\n                    pred2 = model.predict(torch.flip(X, dims=[-1]))[0].squeeze()\n                    preds = (pred1 + pred2) / 2\n                else: preds = pred1\n                pred[:, idx] = preds.cpu()\n            if geomeanpredict:\n                predictions.append(pred.prod(dim=-1)**(1/pred.shape[-1]))\n            else:\n                predictions.append(pred.mean(dim=-1))\n            if idx >= max_batches:\n                break\n        return torch.concat(predictions).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:12.696433Z","iopub.execute_input":"2023-02-19T02:05:12.697077Z","iopub.status.idle":"2023-02-19T02:05:12.718186Z","shell.execute_reply.started":"2023-02-19T02:05:12.697040Z","shell.execute_reply":"2023-02-19T02:05:12.717092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresmax = np.max(thresholds)\nthresmean = np.mean(thresholds)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:12.723444Z","iopub.execute_input":"2023-02-19T02:05:12.726226Z","iopub.status.idle":"2023-02-19T02:05:12.733183Z","shell.execute_reply.started":"2023-02-19T02:05:12.726190Z","shell.execute_reply":"2023-02-19T02:05:12.732139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ds_test = BreastCancerDataSet(df, save_path, get_transforms(False))\nds_test = BreastCancerDataSet(df, save_path, aug_resize_norm)\nmodels_pred = models_predict(models, ds_test)\nmodels_pred","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:12.738507Z","iopub.execute_input":"2023-02-19T02:05:12.740802Z","iopub.status.idle":"2023-02-19T02:05:19.439518Z","shell.execute_reply.started":"2023-02-19T02:05:12.740767Z","shell.execute_reply":"2023-02-19T02:05:19.433229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cancer'] = models_pred\n\n\ndf_sub = df.groupby('prediction_id')[['cancer']].mean()\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:19.441059Z","iopub.execute_input":"2023-02-19T02:05:19.441874Z","iopub.status.idle":"2023-02-19T02:05:19.472897Z","shell.execute_reply.started":"2023-02-19T02:05:19.441644Z","shell.execute_reply":"2023-02-19T02:05:19.471983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if top3:\n    sup = df.groupby('patient_id')[['cancer']]\n    for key, val in sup:\n        ids = list(df.loc[df['patient_id'] == key]['prediction_id'])\n        top_3 = np.sort(list(df.loc[df['patient_id'] == key]['cancer']))[:-1].mean()\n        for idx in ids:\n            df_sub.loc[idx, 'cancer'] = top_3","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:12:05.389517Z","iopub.execute_input":"2023-02-19T02:12:05.390239Z","iopub.status.idle":"2023-02-19T02:12:05.400218Z","shell.execute_reply.started":"2023-02-19T02:12:05.390203Z","shell.execute_reply":"2023-02-19T02:12:05.398853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if geomeanpatient:\n    df_sup = df.groupby('prediction_id')\n    for key, val in df_sup:\n        arr = val['cancer'].to_numpy()\n        df_sub.loc[key, 'cancer'] = arr.prod()**(1.0/len(arr))\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:19.504717Z","iopub.execute_input":"2023-02-19T02:05:19.505421Z","iopub.status.idle":"2023-02-19T02:05:19.522931Z","shell.execute_reply.started":"2023-02-19T02:05:19.505374Z","shell.execute_reply":"2023-02-19T02:05:19.521960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub['cancer'] = (df_sub.cancer > thresmean).astype(float)\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:19.526952Z","iopub.execute_input":"2023-02-19T02:05:19.527711Z","iopub.status.idle":"2023-02-19T02:05:19.545065Z","shell.execute_reply.started":"2023-02-19T02:05:19.527672Z","shell.execute_reply":"2023-02-19T02:05:19.544021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv('submission.csv', index=True)\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-02-19T02:05:19.548830Z","iopub.execute_input":"2023-02-19T02:05:19.551454Z","iopub.status.idle":"2023-02-19T02:05:20.856174Z","shell.execute_reply.started":"2023-02-19T02:05:19.551421Z","shell.execute_reply":"2023-02-19T02:05:20.854784Z"},"trusted":true},"execution_count":null,"outputs":[]}]}